{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73f8d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from numpy.linalg import norm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee470377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    def relu(self, X):\n",
    "        \"\"\"\n",
    "        Memberikan nilai output berupa fungsi ReLU dari X\n",
    "        \n",
    "        Parameter:\n",
    "        X: Numpy 2D Array berukuran (jumlah fitur, jumlah data)\n",
    "        \n",
    "        Return:\n",
    "        Y: Numpy 2D Array yang merupakan output dari fungsi ReLU\n",
    "        \"\"\"\n",
    "        Y = np.maximum(X, 0)\n",
    "        return Y\n",
    "    \n",
    "    def softmax(self, X):\n",
    "        \"\"\"\n",
    "        Memberikan nilai output berupa fungsi Softmax dari X\n",
    "        \n",
    "        Parameter:\n",
    "        X: Numpy 2D Array berukuran (jumlah fitur, jumlah data)\n",
    "        \n",
    "        Return:\n",
    "        Y: Numpy 2D Array yang merupakan output dari fungsi Softmax\n",
    "        \"\"\"\n",
    "        # Menghindari overflow (https://www.techopedia.com/definition/663/overflow-error#:~:text=In%20computing%2C%20an%20overflow%20error,of%20its%20ability%20to%20handle.)\n",
    "        X -= np.max(X, axis=0, keepdims=True)\n",
    "        # Perhitungan\n",
    "        exp_X = np.exp(X)\n",
    "        sum_exp_X = np.sum(exp_X, axis=0, keepdims=True)\n",
    "        Y = exp_X / sum_exp_X\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a959c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def categorical_crossentropy(self, Y_pred, Y_true):\n",
    "        \"\"\"\n",
    "        Memberikan nilai output metrik categorical crossentropy dengan membandingkan Y_pred dengan Y_true\n",
    "        \n",
    "        Parameter:\n",
    "        Y_pred: Numpy 2D Array berukuran (jumlah fitur, jumlah data) yang merupakan hasil prediksi\n",
    "        Y_true: Numpy 2D Array berukuran (jumlah fitur, jumlah data) yang merupakan nilai target pada data\n",
    "        \n",
    "        Return:\n",
    "        cost: Nilai skalar yang merupakan hasil output dari categorical crossentropy\n",
    "        \"\"\"\n",
    "        # Perhitungan\n",
    "        cross_entropy = -np.sum(Y_true * np.log(Y_pred))\n",
    "        cost = cross_entropy / Y_true.shape[1]\n",
    "        return cost\n",
    "\n",
    "    def accuracy(self, Y_pred, Y_true):\n",
    "        \"\"\"\n",
    "        Memberikan nilai output metrik akurasi\n",
    "        \n",
    "        Parameter:\n",
    "        Y_pred: Numpy 2D Array berukuran (jumlah fitur, jumlah data) yang merupakan hasil prediksi\n",
    "        Y_true: Numpy 2D Array berukuran (jumlah fitur, jumlah data) yang merupakan nilai target pada data\n",
    "        \n",
    "        Return:\n",
    "        acc: Nilai skalar yang merupakan hasil output dari akurasi\n",
    "        \"\"\"\n",
    "        pred_matrix = Y_pred == np.max(Y_pred, axis=0)\n",
    "        acc = np.sum(pred_matrix * Y_true) / Y_pred.shape[1]\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417a4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(DIR, image_size=(100, 100)):\n",
    "    images_matrix = []\n",
    "    labels_matrix = []\n",
    "    for subdir in os.listdir(DIR):\n",
    "        SUBDIR = DIR + f\"/{subdir}\"\n",
    "        for image_file in os.listdir(SUBDIR):\n",
    "            # Labels\n",
    "            label_vector = np.zeros((len(TRUE_LABELS)))\n",
    "            label_idx = TRUE_LABELS[subdir]\n",
    "            label_vector[label_idx] = 1\n",
    "            labels_matrix.append(label_vector)\n",
    "            # Images\n",
    "            image = Image.open(f\"{SUBDIR}/{image_file}\")\n",
    "            image = image.resize(image_size)\n",
    "            image = np.asarray(image, dtype=np.float64)\n",
    "            image /= 255.0\n",
    "            images_matrix.append(image)\n",
    "    images_matrix = np.expand_dims(images_matrix, axis=-1)\n",
    "    labels_matrix = np.array(labels_matrix)\n",
    "    \n",
    "    # Randomize the data\n",
    "    random_num = random.randint(0, 42)\n",
    "    X, Y = shuffle(images_matrix, labels_matrix, random_state=random_num)\n",
    "    return X, Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efa4b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(X, W, B=np.array(0)):\n",
    "    conv_images = np.zeros((X.shape[0], X.shape[1] - W.shape[1] + 1, \\\n",
    "                                 X.shape[2] - W.shape[2] + 1, W.shape[0]))\n",
    "    img_len, conv_x, conv_y, filters = conv_images.shape\n",
    "    for idx in range(img_len):\n",
    "        for i in range(conv_x):\n",
    "            for j in range(conv_y):\n",
    "                sub_image = X[idx, i:i+W.shape[1], j:j+W.shape[2], :]\n",
    "                conv_images[idx, i, j, :] = np.sum(sub_image * W, axis=(1, 2, 3)) + B.flatten()\n",
    "    return conv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0827c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling(X, pool_size=(2, 2)):\n",
    "    \"\"\"\n",
    "    Mengembalikan matriks citra hasil max pooling\n",
    "\n",
    "    Parameter:\n",
    "    X: Matriks Input Numpy Array 4D berukuran (jumlah data, panjang pixel, lebar pixel, anchor)\n",
    "    pool_size: Ukuran sub-matriks Numpy Array 2D yang akan diterapkan operasi max pooling\n",
    "\n",
    "    Return:\n",
    "    pooled_images: Matriks Pooling Numpy Array 4D\n",
    "    \"\"\"\n",
    "    img_len, pooled_x, pooled_y, anchors = X.shape[0], X.shape[1] // pool_size[0], X.shape[2] // pool_size[1], X.shape[-1]\n",
    "    pooled_images = np.zeros((img_len, pooled_x, pooled_y, anchors))\n",
    "\n",
    "    for idx in range(img_len):  \n",
    "        for i in range(0, pooled_x*pool_size[0], pool_size[0]):\n",
    "            for j in range(0, pooled_y*pool_size[1], pool_size[1]):\n",
    "                sub_image = X[idx, i:i+pool_size[0], j:j+pool_size[1], :]\n",
    "                pooled_images[idx, int(i/pool_size[0]), int(j/pool_size[1]), :] = np.max(sub_image, axis=(0, 1))\n",
    "    return pooled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7025d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './New Data - Copy/Train'\n",
    "TEST_DIR = './New Data - Copy/Test'\n",
    "dirs = (TRAIN_DIR, TEST_DIR)\n",
    "\n",
    "TRUE_LABELS = {}\n",
    "\n",
    "# Assign each photo to corresponding labels\n",
    "for directory in dirs:\n",
    "    for label, subdir in enumerate(os.listdir(directory)):\n",
    "        TRUE_LABELS[subdir] = label\n",
    "        \n",
    "train_images, train_labels = data_preprocessing(TRAIN_DIR, image_size=(14, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1f6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images[-10:]\n",
    "train_labels = train_labels[:, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45159e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(4, 3, 3, 1) * 0.01\n",
    "B1 = np.random.randn(4, 1) * 0.01\n",
    "\n",
    "W2 = np.random.randn(16, 3, 3, 4) * 0.01\n",
    "B2 = np.random.randn(16, 1) * 0.01\n",
    "\n",
    "W3 = np.random.randn(64, 64) * 0.01\n",
    "B3 = np.random.randn(64, 1) * 0.01\n",
    "\n",
    "W4 = np.random.randn(3, 64) * 0.01\n",
    "B4 = np.random.randn(3, 1) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554b74f",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "09e57804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1\n",
      "Done 2\n",
      "Done 3\n",
      "Done 4\n"
     ]
    }
   ],
   "source": [
    "parameter = B1.copy()\n",
    "dB1_approx = np.zeros_like(parameter)\n",
    "\n",
    "for i in range(parameter.shape[0]):\n",
    "    for j in range(parameter.shape[1]):\n",
    "#         for k in range(parameter.shape[2]):\n",
    "#             for l in range(parameter.shape[3]):\n",
    "        E = np.zeros_like(parameter)\n",
    "        E[i, j] = 1\n",
    "\n",
    "        # Convolutional Layer\n",
    "        z1 = convolution(train_images, W1, B1)\n",
    "        a1 = Activation().relu(z1)\n",
    "\n",
    "        z1_plus = convolution(train_images, W1, B1 + 1e-7 * E)\n",
    "        a1_plus = Activation().relu(z1_plus)\n",
    "\n",
    "        z1_minus = convolution(train_images, W1, B1 - 1e-7 * E)\n",
    "        a1_minus = Activation().relu(z1_minus)\n",
    "\n",
    "        # Max Pooling Layer\n",
    "        a2 = pooling(a1)\n",
    "        a2_plus = pooling(a1_plus)\n",
    "        a2_minus = pooling(a1_minus)\n",
    "\n",
    "        # Convolution Layer\n",
    "        z3 = convolution(a2, W2, B2)\n",
    "        a3 = Activation().relu(z3)\n",
    "\n",
    "        z3_plus = convolution(a2_plus, W2, B2)\n",
    "        a3_plus = Activation().relu(z3_plus)\n",
    "\n",
    "        z3_minus = convolution(a2_minus, W2, B2)\n",
    "        a3_minus = Activation().relu(z3_minus)\n",
    "\n",
    "        # Max Pooling Layer\n",
    "        a4 = pooling(a3)\n",
    "        a4_plus = pooling(a3_plus)\n",
    "        a4_minus = pooling(a3_minus)\n",
    "\n",
    "        # Flatten\n",
    "        a5 = np.reshape(a4, (a4.shape[0], -1)).T\n",
    "        a5_plus = np.reshape(a4_plus, (a4.shape[0], -1)).T\n",
    "        a5_minus = np.reshape(a4_minus, (a4.shape[0], -1)).T\n",
    "\n",
    "        # Dense 1\n",
    "        z6 = W3 @ a5 + B3\n",
    "        a6 = Activation().relu(z6)\n",
    "\n",
    "        z6_plus = (W3) @ a5_plus + (B3)\n",
    "        a6_plus = Activation().relu(z6_plus)\n",
    "\n",
    "        z6_minus = (W3) @ a5_minus + (B3)\n",
    "        a6_minus = Activation().relu(z6_minus)\n",
    "\n",
    "        # Dense 2\n",
    "        z7 = W4 @ a6 + B4\n",
    "        a7 = Activation().softmax(z7)\n",
    "\n",
    "        z7_plus = (W4) @ a6_plus + (B4)\n",
    "        a7_plus = Activation().softmax(z7_plus)\n",
    "\n",
    "        z7_minus = (W4) @ a6_minus + (B4)\n",
    "        a7_minus = Activation().softmax(z7_minus)\n",
    "\n",
    "        # Gradient Checking\n",
    "        loss_plus = Metrics().categorical_crossentropy(a7_plus, train_labels)\n",
    "        loss_minus = Metrics().categorical_crossentropy(a7_minus, train_labels)\n",
    "\n",
    "        dB1_approx[i, j] = (loss_plus - loss_minus) / 2e-7\n",
    "    print(f\"Done {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d5dd4",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f91e3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = a7.shape[1]\n",
    "dz7 = a7 - train_labels\n",
    "dW4 = dz7 @ a6.T / img \n",
    "dB4 = np.sum(dz7, axis=1, keepdims=True) / img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab2542ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_z6 = np.where(z6 >= 0, 1, 0)\n",
    "dz6 = (W4.T @ dz7) * diff_z6\n",
    "dW3 = dz6 @ a5.T / img\n",
    "dB3 = np.sum(dz6, axis=1, keepdims=True) / img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2782439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz5 = W3.T @ dz6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "950ace30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dz4 = np.reshape(dz5.T, newshape=a4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f2f1e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = np.zeros_like(a3)\n",
    "img_len, m, n, anchors = a3.shape\n",
    "\n",
    "# Jika ukuran output adalah ganjil\n",
    "if m % 2 == 1:\n",
    "    m -= 1\n",
    "if n %2 == 1:\n",
    "    n -= 1\n",
    "\n",
    "for idx in range(img_len):\n",
    "    for i in range(0, m, 2):\n",
    "        for j in range(0, n, 2):\n",
    "            sub_C = a3[idx, i:i+2, j:j+2, :]\n",
    "            dC[idx, i:i+2, j:j+2, :] = np.where(sub_C == np.max(sub_C, axis=(0, 1), keepdims=True),\n",
    "                                                np.reshape(dz4[idx, int(i/2), int(j/2), :], (1, 1, -1)), 0) /\\\n",
    "                                       np.where(np.sum(sub_C == np.max(sub_C, axis=(0, 1), keepdims=True), axis=(0, 1), keepdims=True) > 1, 2, 1)\n",
    "\n",
    "# dC/dZ\n",
    "dCdZ = np.where(z3 >= 0, 1, 0)\n",
    "\n",
    "# dZ = dcost/dZ\n",
    "dz3 = dC * dCdZ\n",
    "\n",
    "dW2 = convolution(a2.T, dz3.T).T / img_len\n",
    "dB2 = np.expand_dims(np.sum(dz3, axis=(0, 1, 2)), axis=-1) / img_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03839c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_size = 2\n",
    "padded_dZ = np.pad(dz3, ((0, 0), (padded_size, padded_size), (padded_size, padded_size), (0, 0)))\n",
    "rotated_W = np.rot90(W2, axes=(1, 2), k=2)\n",
    "dz2 = convolution(X=padded_dZ, W=rotated_W.swapaxes(0, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bff9a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = np.zeros_like(a1)\n",
    "img_len, m, n, anchors = a1.shape\n",
    "\n",
    "# Jika ukuran output adalah ganjil\n",
    "if m % 2 == 1:\n",
    "    m -= 1\n",
    "if n %2 == 1:\n",
    "    n -= 1\n",
    "\n",
    "for idx in range(img_len):\n",
    "    for i in range(0, m, 2):\n",
    "        for j in range(0, n, 2):\n",
    "            sub_C = a1[idx, i:i+2, j:j+2, :]\n",
    "            dC[idx, i:i+2, j:j+2, :] = np.where(sub_C == np.max(sub_C, axis=(0, 1), keepdims=True),\n",
    "                                                np.reshape(dz2[idx, int(i/2), int(j/2), :], (1, 1, -1)), 0) /\\\n",
    "                                       np.where(np.sum(sub_C == np.max(sub_C, axis=(0, 1), keepdims=True), axis=(0, 1), keepdims=True) > 1, 2, 1)\n",
    "            \n",
    "# dC/dZ\n",
    "dCdZ = np.where(z1 >= 0, 1, 0)\n",
    "\n",
    "# dZ = dcost/dZ\n",
    "dz1 = dC * dCdZ\n",
    "\n",
    "dW1 = convolution(train_images.T, dz1.T).T / img\n",
    "dB1 = np.expand_dims(np.sum(dz1, axis=(0, 1, 2)), axis=-1) / img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62215bcf",
   "metadata": {},
   "source": [
    "### Hasil Gradient Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b7f97",
   "metadata": {},
   "source": [
    "#### Dense 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e0616fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.127957484298917e-09"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz7_approx - dz7 / img) / (norm(dz7_approx) + norm(dz7 / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af5a9ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4831166319301284e-07"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dW4_approx - dW4) / (norm(dW4_approx) + norm(dW4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be303deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.758099447419225e-09"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dB4_approx - dB4) / (norm(dB4_approx) + norm(dB4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e9842c",
   "metadata": {},
   "source": [
    "#### Dense 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "091841d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7148207080823337e-07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz6_approx - dz6 / img) / (norm(dz6_approx) + norm(dz6 / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec388bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7294503335195843e-05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dW3_approx - dW3) / (norm(dW3_approx) + norm(dW3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43e530bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5705167304957233e-08"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dB3_approx - dB3) / (norm(dB3_approx) + norm(dB4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c122e41",
   "metadata": {},
   "source": [
    "#### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3cdd6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.830466768379444e-06"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz5_approx - dz5 / img) / (norm(dz5_approx) + norm(dz5 / img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b08dff8",
   "metadata": {},
   "source": [
    "#### Max Pooling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4bc19f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.830466768379444e-06"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz4_approx - dz4 / img) / (norm(dz4_approx) + norm(dz4 / img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab64cc",
   "metadata": {},
   "source": [
    "#### Convolutional Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a77feb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5486409591515676e-05"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(da3_approx - dC / img) / (norm(da3_approx) + norm(dC / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba83411e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.335795947955409e-06"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz3_approx - dz3 / img) / (norm(dz3_approx) + norm(dz3 / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4851e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.393350100422645e-05"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dW2_approx - dW2) / (norm(dW2_approx) + norm(dW2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fe749e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.475530188681731e-06"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dB2_approx - dB2) / (norm(dB2_approx) + norm(dB2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2cdb5",
   "metadata": {},
   "source": [
    "#### Max Pooling Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f7066fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00036863762060196457"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz2_approx - dz2 / img) / (norm(dz2_approx) + norm(dz2 / img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3829c588",
   "metadata": {},
   "source": [
    "#### Convolutional Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e8532ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006994379695956223"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(da1_approx - dC / img) / (norm(da1_approx) + norm(dC / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d15ab676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005277462897791574"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dz1_approx - dz1 / img) / (norm(dz1_approx) + norm(dz1 / img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9440280d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0730961500408985e-05"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dW1_approx - dW1) / (norm(dW1_approx) + norm(dW1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00c2a040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5852971516203433"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(dB1_approx - dB1) / (norm(dB1_approx) + norm(dB1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
